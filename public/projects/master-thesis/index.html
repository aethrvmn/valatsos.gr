<!DOCTYPE html>
<html lang="en"><head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <style>
        :root {
            --accent-color: #1b9470;
        }
    </style>

    
    
    
    
    
    

    
    
    <title>Vasilis Valatsos | Vasilis Valatsos</title>
    
    <meta name="description" content="Data Science | Machine Learning | Reinforcement Learning">
    <meta name="keywords" content=''>

    <meta property="og:url" content="https://www.valatsos.gr/projects/master-thesis/">
    <meta property="og:type" content="website">
    <meta property="og:title" content="Vasilis Valatsos">
    <meta property="og:description" content="Data Science | Machine Learning | Reinforcement Learning">
    <meta property="og:image" content="https://www.valatsos.gr/images/logo.png">
    <meta property="og:image:secure_url" content="https://www.valatsos.gr/images/logo.png">

    <meta name="twitter:card" content="summary_large_image">
    <meta name="twitter:title" content="Vasilis Valatsos">
    <meta name="twitter:description" content="Data Science | Machine Learning | Reinforcement Learning">
    <meta property="twitter:domain" content="https://www.valatsos.gr/projects/master-thesis/">
    <meta property="twitter:url" content="https://www.valatsos.gr/projects/master-thesis/">
    <meta name="twitter:image" content="https://www.valatsos.gr/images/logo.png">

    
    <link rel="canonical" href="https://www.valatsos.gr/projects/master-thesis/" />

    
    <link rel="stylesheet" type="text/css" href="/css/normalize.min.css" media="print">

    
    <link rel="stylesheet" type="text/css" href="/css/main.min.css">

    
    <link id="dark-theme" rel="stylesheet" href="/css/dark.min.css">

    
    <script src="/js/bundle.min.224c8e70fed292d18d7d9ae1b36797c99144e0be1117e2ea2c428379c8496551.js" integrity="sha256-IkyOcP7SktGNfZrhs2eXyZFE4L4RF&#43;LqLEKDechJZVE="></script>

    
    
</head>
<body>
        <script type="text/javascript">
            
            setThemeByUserPref();
        </script><header class="header">
    <nav class="header-nav">

        
        <div class="avatar">
            <a href="https://www.valatsos.gr/">
                <img src='/images/logo.png' alt="avatar" />
            </a>
        </div>
        

        <div class="nav-title">
            <a class="nav-brand" href="https://www.valatsos.gr/">Vasilis Valatsos</a>
        </div>

        <div class="nav-links">
            
            <div class="nav-link">
                <a href="https://www.valatsos.gr/"><span data-feather='home'></span> Home </a>
            </div>
            
            <div class="nav-link">
                <a href="https://www.valatsos.gr/projects/"><span data-feather='code'></span> Projects </a>
            </div>
            
            <div class="nav-link">
                <a href="https://www.valatsos.gr/blog/"><span data-feather='feather'></span> Blog </a>
            </div>
            
            <div class="nav-link">
                <a href="https://www.valatsos.gr/about/"><span data-feather='hash'></span> About </a>
            </div>
            
            <div class="nav-link">
                <a href="https://www.valatsos.gr/index.xml"><span data-feather='rss' /> RSS </a>
            </div>
            

            <span class="nav-icons-divider"></span>
            <div class="nav-link dark-theme-toggle">
                <span id="dark-theme-toggle-screen-reader-target" class="sr-only"></span>
                <a>
                    <span id="theme-toggle-icon" data-feather="moon"></span>
                </a>
            </div>

             <div class="nav-link" id="hamburger-menu-toggle">
                <span id="hamburger-menu-toggle-screen-reader-target" class="sr-only">menu</span>
                <a>
                    <span data-feather="menu"></span>
                </a>
            </div>

            
            <ul class="nav-hamburger-list visibility-hidden">
                
                <li class="nav-item">
                    <a href="https://www.valatsos.gr/"><span data-feather='home'></span> Home </a>
                </li>
                
                <li class="nav-item">
                    <a href="https://www.valatsos.gr/projects/"><span data-feather='code'></span> Projects </a>
                </li>
                
                <li class="nav-item">
                    <a href="https://www.valatsos.gr/blog/"><span data-feather='feather'></span> Blog </a>
                </li>
                
                <li class="nav-item">
                    <a href="https://www.valatsos.gr/about/"><span data-feather='hash'></span> About </a>
                </li>
                
                <li class="nav-item">
                    <a href="https://www.valatsos.gr/index.xml"><span data-feather='rss' /> RSS </a>
                </li>
                
                <li class="nav-item dark-theme-toggle">
                    <span id="dark-theme-toggle-screen-reader-target" class="sr-only">theme</span>
                    <a>
                        <span id="theme-toggle-icon" data-feather="moon"></span>
                    </a>
                </li>
            </ul>

        </div>
    </nav>
</header>
<main id="content">
    

    <div class="post container">

    <div class="post-header-section">
        <h1></h1>
    </div>

    <div class="post-content">
        <p>
            <h1 id="reinforcement-learning-theory-and-implementation-in-a-custom-environment">Reinforcement Learning: Theory and Implementation in a Custom Environment</h1>
<p>You can find the thesis <a href="/pdfs/mthesis.pdf">here</a> and the code <a href="https://github.com/aethrvmn/GodotPneumaRL">here</a></p>
<h2 id="abstract">Abstract</h2>
<p>Reinforcement Learning (RL) is a subcategory of Machine Learning that consistently surpasses human performance and demonstrates superhuman understanding in various environments and datasets. Its applications span from mastering games like Go and Chess to optimizing real-world operations in robotics, finance, and healthcare. The adaptability and efficiency of RL algorithms in dynamic and complex scenarios highlight their transformative potential across multiple domains.</p>
<p>In this thesis, we present some core concepts of Reinforcement Learning.</p>
<p>First, we introduce the mathematical foundation of Reinforcement Learning (RL) through the Multi-Armed Bandit (MAB) problem, which serves as a simplified model for decision-making problems without state transitions, focusing solely on the trade-off between exploration and exploitation. We then extend the discussion to the more complex Markov Decision Processes (MDPs), which provide a formal framework for modeling decision-making problems where outcomes are partly random and partly under the control of a decision-maker, involving state transitions influenced by actions. Finally, we give an overview of the two main branches of Reinforcement Learning: value-based methods, which focus on estimating the value of states or state-action pairs, and policy-based methods, which directly optimize the policy that dictates the agent&rsquo;s actions.</p>
<p>We focus on Proximal Policy Optimization (PPO), which is the <em>de facto</em> baseline algorithm in modern RL literature due to its robustness and ease of implementation. We discuss its potential advantages, such as improved sample efficiency and stability, as well as its disadvantages, including sensitivity to hyper-parameters and computational overhead. We emphasize the importance of fine-tuning PPO to achieve optimal performance.</p>
<p>We demonstrate the application of these concepts within <em>Pneuma</em>, a custom-made environment specifically designed for this thesis. <em>Pneuma</em> aims to become a research base for independent Multi-Agent Reinforcement Learning (MARL), where multiple agents learn and interact within the same environment. We outline the requirements for such environments to support MARL effectively and detail the modifications we made to the baseline PPO method, as presented by OpenAI, to facilitate agent convergence for a single-agent level.</p>
<p>Finally, we discuss the potential for future enhancements to the <em>Pneuma</em> environment to increase its complexity and realism, aiming to create a more RPG-like setting, optimal for training agents in complex, multi-objective, and multi-step tasks.</p>

        </p>
    </div>
</div>


<aside class="post-toc">
    <nav id="toc">
        <nav id="TableOfContents">
  <ul>
    <li><a href="#reinforcement-learning-theory-and-implementation-in-a-custom-environment">Reinforcement Learning: Theory and Implementation in a Custom Environment</a>
      <ul>
        <li><a href="#abstract">Abstract</a></li>
      </ul>
    </li>
  </ul>
</nav>
    </nav>
</aside>



        </main><footer class="footer">
    
    

    
    <span>&copy; 2024 Vasilis Valatsos</span>
    
    <span>
        Made with &#10084;&#65039; using <a target="_blank" href="https://github.com/526avijitgupta/gokarna">Gokarna</a>
    </span>
</footer>
</body>
</html>
